# ğŸ“° Fake News Detection with BERT + GPT Reasoning

This project is an advanced fake news classification system that combines the power of **BERT** (for prediction) with **Gemma/GPT-style reasoning** to explain whether a news article is real or fake â€” just like Grok AI!

---

## ğŸš€ Features

- âœ… Accurate prediction using fine-tuned BERT on `True.csv` and `Fake.csv`
- ğŸ§  LLM-based explanation using Google Gemma 3B/12B (via Ollama)
- ğŸ“Š Confidence scores for predictions
- âš¡ Fast Flask web interface with modern UI
- ğŸ“‚ Organized directory structure for deployment & reproducibility

---

## ğŸ—ï¸ Project Structure

FakeNews-BERT/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ True.csv
â”‚ â””â”€â”€ Fake.csv
â”œâ”€â”€ model/
â”‚ â””â”€â”€ best_model/ (BERT model files)
â”œâ”€â”€ web_app/
â”‚ â”œâ”€â”€ templates/
â”‚ â”‚ â””â”€â”€ index.html
â”‚ â”œâ”€â”€ static/
â”‚ â”‚ â””â”€â”€ style.css
â”‚ â”œâ”€â”€ app.py
â”‚ â””â”€â”€ llm_reasoning.py
â”œâ”€â”€ bert_fakenews.py
â”œâ”€â”€ predict.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

yaml
Copy
Edit

---

## ğŸ’» How to Run

1. **Clone the repo**  
   ```bash
   git clone https://github.com/priyanshu044-4/FakeNews-BERT.git
   cd FakeNews-BERT
Install dependencies

bash
Copy
Edit
pip install -r requirements.txt
Start Flask app

bash
Copy
Edit
cd web_app
python app.py
(Optional) Run Ollama for LLM reasoning

bash
Copy
Edit
ollama run gemma:12b
ğŸŒ Web App Preview
Paste your news article, hit "Analyze" and see:

ğŸ“¢ Real or Fake prediction

ğŸ’¡ LLM reasoning behind it (Grok-style)

ğŸ¤– Model Training (BERT)
We use bert-base-uncased fine-tuned on the combined dataset of true and fake news articles:

512-token truncation

Adam optimizer

Epochs: 3â€“5

Custom bert_fakenews.py for training pipeline

ğŸ“¦ Requirements
Python 3.10+

Transformers

Torch

Flask

Ollama (for LLM reasoning)

Install all dependencies with:

bash
Copy
Edit
pip install -r requirements.txt
ğŸ§  LLM Reasoning (Gemma via Ollama)
To enable explanation with LLM:

Install Ollama

Pull the model:

bash
Copy
Edit
ollama pull gemma:12b
Ensure it's running on http://localhost:11434

If LLM response fails or times out, fallback is a default message.

ğŸ“Š Dataset
Used only:

data/Fake.csv

data/True.csv

You donâ€™t need to scrape or use external news APIs. This project is purely local.

ğŸ‘¨â€ğŸ’» Author
Priyanshu Kumar
GitHub | LinkedIn

ğŸ“„ License
MIT License
